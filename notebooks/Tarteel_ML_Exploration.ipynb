{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarteel-ML Dataset Exploration\n",
    "\n",
    "This notebook walks through cloning the repository, downloading the dataset, exploring metadata and audio, visualizing features, and saving artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup: Clone Repo and Install Dependencies\n",
    "!git clone https://github.com/Tarteel-io/Tarteel-ML.git\n",
    "%cd Tarteel-ML\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Download Tarteel Dataset\n",
    "from scripts.download_data import download_tarteel_data\n",
    "\n",
    "# By default downloads into `data/` directory\n",
    "download_tarteel_data(output_dir='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Inspect Metadata\n",
    "import pandas as pd\n",
    "meta = pd.read_csv('data/metadata.csv')\n",
    "meta.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show basic statistics\n",
    "meta['duration_sec'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Audio Playback & Duration Distribution\n",
    "import IPython.display as ipd\n",
    "\n",
    "# Play a sample file\n",
    "ipd.Audio('data/audio/reciter_A/001.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(meta['duration_sec'], bins=50)\n",
    "plt.xlabel('Duration (sec)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Audio Duration Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Spectrogram Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa, librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = 'data/audio/reciter_A/001.wav'\n",
    "y, sr = librosa.load(path, sr=16000)\n",
    "S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "S_db = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(S_db, sr=sr, y_axis='mel', x_axis='time')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Mel-Spectrogram of 001.wav')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Segment-Level Preview\n",
    "Load transcript JSON and show a few segments alongside short audio snippets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data/transcripts/reciter_A.json') as f:\n",
    "    transcripts = json.load(f)\n",
    "\n",
    "# Display first 5 segments\n",
    "for seg in transcripts[:5]:\n",
    "    start, end = seg['start_time'], seg['end_time']\n",
    "    print(f\"Verse {seg['verse_id']}: {seg['text']} ({start}-{end}s)\")\n",
    "    display(ipd.Audio('data/audio/reciter_A/001.wav', rate=sr, autoplay=False, normalize=True))\n",
    "    break  # remove break to iterate further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Sample Metadata\n",
    "Export a random subset for reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = meta.sample(10, random_state=42)\n",
    "sample.to_csv('sample_metadata.csv', index=False)\n",
    "print(\"Sample metadata saved to sample_metadata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "- Extend to multiple reciters\n",
    "- Extract features (MFCC, pitch)\n",
    "- Build initial ASR or classification baseline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
